<?xml version="1.0" encoding="UTF-8"?>
<document id="00104109">
Warto w tym miejscu podkreślić, że ta prostota realizacji nie pociąga za sobą lepszych wyników znakowania fraz niż <phrase id="484558">znakowania morfosyntaktycznego</phrase>. Miałoby to miejsce gdyby oceniać osiągi modułu znakowania fraz za pomocą trafności rozumianej jako procent segmentów z poprawnie przypisanymi <phrase id="484559">tagami IOB2</phrase>. Miary tej się jednak nie używa, a stosowana powszechnie miara F implikuje bardziej surowe kary. Przykładowo, jeśli mamy do czynienia z bardzo długą frazą, a moduł znakowania zwróci poprawnie wszystkie znaczniki IOB2 z wyjątkiem jednego, to cała fraza zostanie potraktowana jako nietrafiona. Trafność przypisywania znaczników nie jest dobrym sposobem oceny oznakowania frazami, gdyż stosunkowo łatwo osiągnąć wysokie wartości, jeśli prawidłowo rozpoznamy tagi O oznaczające, że przez segmenty nie przebiega żadna fraza. W szczególności jeśli wartość trafności podalibyśmy dla problemu znakowania pojedynczej frazy, która występuje w tekście nieczęsto, ,,parser'', który każdemu segmentowi przypisuje znacznik O, uzyskałby wysoką ocenę. 

Ramshaw i Marcus (1995) pokazali nie tylko sposób reprezentacji fraz za pomocą znaczników IOB1, ale także sposób, w jaki można użyć algorytmu Brilla znanego ze znakowania morfosyntaktycznego do znakowania fraz. Przypomnijmy, że <phrase id="484562">algorytm Brilla</phrase> pozwala na indukcję reguł, które dokonują kolejnych poprawek istniejącego już oznakowania ciągu segmentów (por. str. 32). Algorytm wymaga zastosowania heurystyki, która pozwala na początkowe przypisanie znaczników -- przypisanie, które korygować będą reguły w kolejnych iteracjach. W przypadku algorytmu z pracy (Ramshaw i Marcus, 1995) heurystyka ta korzystała z oznakowania morfosyntaktycznego: danemu segmentowi w przypisujemy znacznik IOB1, który najczęściej przypisano w danych uczących segmentom oznakowanym tagiem morfosyntaktycznym, który tager przypisał także segmentowi . Na danych pochodzących z korpusu Wall Street Journal (WSJ) udało się osiągnąć wartość miary F 92,05%. 

Praca (Ramshaw i Marcus, 1995) jest istotna także ze względu na stosowany zbiór danych: wspomniane dane pozyskane z korpusu WSJ wraz z ich podziałem na część uczącą i testową stały się standardowym materiałem testowym, na którym później przetestowano szereg algorytmów znakowania fraz rzeczownikowych. Drugi standardowy zbiór danych został opracowany na potrzeby konferencji-konkursu CoNLL-2000 (Tjong Kim Sang i Buchholz, 2000). Dane te także pochodzą z tego samego fragmentu korpusu WSJ, lecz tym razem tekst oznakowano aż jedenastoma typami fraz. Zbiór ten uwzględnia frazy rzeczownikowe (NP), przyimkowe (PP), przymiotnikowe (AdjP), czasownikowe (VP), przysłówkowe (AdvP), a także kilka mniej typowych fraz, które odpowiadają partykułom, spójnikom itp. (te nietypowe frazy występują w tekście stosunkowo rzadko). W przypadku obu zbiorów danych, część ucząca składa się z 211 727 segmentów, natomiast część testowa zawiera ich 47 377. Dla uproszczenia, pierwszy zbiór danych będziemy nazywać odtąd <phrase id="484570">korpusem WSJ-NP</phrase>, natomiast zbiór drugi -- <phrase id="484569">korpusem CoNLL 2000</phrase>. 
</document>